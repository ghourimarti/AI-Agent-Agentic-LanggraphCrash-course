{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e06ee86",
   "metadata": {},
   "source": [
    "# Build A Basic Chatbot With Langgraph(GRAPH API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71defd",
   "metadata": {},
   "source": [
    "### 1. Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cb63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install typing_extensions\n",
    "# !uv pip install langgraph\n",
    "# !uv pip install langchain_tavily\n",
    "# !uv pip install langchain-groq\n",
    "# !uv pip install langsmith\n",
    "# !uv pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9055239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain Key:       lsv2_...\n",
      "openai_api_key Key:  sk-pr...\n",
      "groq_api_key Key:    gsk_J...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('token.env')  # path to your token.env file\n",
    "\n",
    "langchain_api_key = os.getenv(\"langchain_api_key\")\n",
    "openai_api_keys = os.getenv(\"openai_api_key\")\n",
    "tavily_api_key = os.getenv(\"tavily_api_key\")\n",
    "groq_api_key = os.getenv(\"groq_api_key\")\n",
    "print(\"Langchain Key:      \",langchain_api_key[:5] + \"...\" if langchain_api_key else \"key not found\")\n",
    "print(\"openai_api_key Key: \",openai_api_keys[:5] + \"...\" if openai_api_keys else \"key not found\")\n",
    "print(\"tavily_api_key Key: \",tavily_api_key[:5] + \"...\" if tavily_api_key else \"key not found\")\n",
    "print(\"groq_api_key Key:   \",groq_api_key[:5] + \"...\" if groq_api_key else \"key not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "langchain_api_key = os.getenv(\"langchain_api_key\")\n",
    "openai_api_keys = os.getenv(\"openai_api_key\")\n",
    "\n",
    "print(\"Langchain Key:      \",langchain_api_key[:5] + \"...\" if langchain_api_key else \"key not found\")\n",
    "print(\"openai_api_key Key: \",openai_api_keys[:5] + \"...\" if openai_api_keys else \"key not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c10a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6037a36",
   "metadata": {},
   "source": [
    "### 2. Add State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b393f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages:Annotated[list,add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48161c",
   "metadata": {},
   "source": [
    "### 3. Define LLM and Initiliaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d18f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019A815B1450>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019A815B1E50>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "llm=ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "llm=init_chat_model(\"groq:llama3-8b-8192\")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf528ce",
   "metadata": {},
   "source": [
    "### 4. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af50c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Node Functionality\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf14ad1",
   "metadata": {},
   "source": [
    "### 5. Define Node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b77875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000019A81109940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder=StateGraph(State)\n",
    "\n",
    "## Adding node\n",
    "graph_builder.add_node(\"llmchatbot\",chatbot)\n",
    "\n",
    "## Adding Edges\n",
    "graph_builder.add_edge(START,\"llmchatbot\")\n",
    "graph_builder.add_edge(\"llmchatbot\",END)\n",
    "\n",
    "## compile the graph\n",
    "graph=graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b74dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the graph\n",
    "from IPython.display import Image,display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d91a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='f31f838e-3bf4-4286-971f-4515ce97ddeb'),\n",
      " AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36, 'completion_time': 0.125352065, 'prompt_time': 0.026521139, 'queue_time': 0.38086473099999996, 'total_time': 0.151873204}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--5dceb62f-bad4-4edf-9f1f-8b4c97b7e5f0-0', usage_metadata={'input_tokens': 11, 'output_tokens': 25, 'total_tokens': 36})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "response=graph.invoke({\"messages\":\"Hi\"})\n",
    "pprint(response[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "323b71a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25caf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llmchatbot': {'messages': [AIMessage(content=\"I'm just a language model, I don't have feelings or emotions like humans do, but I'm here to help you with any questions or tasks you have! I'm functioning properly and ready to assist you. How can I help you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 15, 'total_tokens': 66, 'completion_time': 0.203689541, 'prompt_time': 0.012272505, 'queue_time': 0.24820427900000003, 'total_time': 0.215962046}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_8dc6ecaf8e', 'finish_reason': 'stop', 'logprobs': None}, id='run--02877e4f-8344-49ca-8e63-fcfdc82e46f8-0', usage_metadata={'input_tokens': 15, 'output_tokens': 51, 'total_tokens': 66})]}}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi How are you?\"}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd9240e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just an AI, so I don't have emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How about you? How's your day going?\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi How are you?\"}):\n",
    "    for value in event.values():\n",
    "        print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b696d",
   "metadata": {},
   "source": [
    "### Chatbot With Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447e146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:80: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. \"Crawl only the docs.tavily.com subdomain\" ---> [\"^docs\\.tavily\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:99: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. \"Crawl tavily.com but exclude the docs.tavily.com subdomain from the crawl\" ---> [\"^docs\\.tavily\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:231: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. [\"^docs\\.example\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:241: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. [^private\\.example\\.com$]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:80: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. \"Map only the docs.tavily.com subdomain\" ---> [\"^docs\\.tavily\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:99: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. \"Map tavily.com but exclude the docs.tavily.com subdomain from the map\" ---> [\"^docs\\.tavily\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:219: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. [\"^docs\\.example\\.com$\"]\n",
      "d:\\Coursera Courses (NVME)\\LLM freecodecamp\\AI-Agent-Agentic-LanggraphCrash-course\\agent\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:229: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ex. [^private\\.example\\.com$]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is langgraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'What is LangGraph? - IBM',\n",
       "   'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "   'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agentâ€™s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',\n",
       "   'score': 0.94401723,\n",
       "   'raw_content': None},\n",
       "  {'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "   'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "   'content': 'LangGraph is a Python library that helps you build applications like chatbots or AI agents by organizing their logic step-by-step using state machine model. This step configures your Gemini API key and then we create a simple function ask_gemini that takes user input, sends it to the Gemini model and returns the AI-generated response. Creates a state structure with three fields: question, classification and response which flows through the LangGraph. import matplotlib.pyplot as plt from langgraph.graph import StateGraph\\u200bbuilder = StateGraph(GraphState)builder.add_node(\"classify\", classify)builder.add_node(\"respond\", respond)builder.set_entry_point(\"classify\")builder.add_edge(\"classify\", \"respond\")builder.set_finish_point(\"respond\")app = builder.compile()\\u200bdef visualize_workflow(builder): G = nx.DiGraph()\\u200b for node in builder.nodes: G.add_node(node) for edge in builder.edges: G.add_edge(edge[0], edge[1])\\u200b pos = nx.spring_layout(G) nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=12, font_weight=\"bold\", arrows=True)  plt.title(\"Langchain Workflow Visualization\") plt.show()\\u200bvisualize_workflow(builder)',\n",
       "   'score': 0.91137725,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 2.01}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool=TavilySearch(max_results=2)\n",
    "tool.invoke(\"What is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd185da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom function\n",
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int: output int\n",
    "    \"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[tool,multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046be79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19544d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stategraph\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",END)\n",
    "\n",
    "## compile the graph\n",
    "graph=builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is the recent ai news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6168c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is 5 multiplied by 2\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Give me the recent ai news and then multiply 5 by 10\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd11d4",
   "metadata": {},
   "source": [
    "### ReAct Agent Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stategraph\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "\n",
    "## compile the graph\n",
    "graph=builder.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Give me the recent ai news and then multiply 5 by 10\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb80059",
   "metadata": {},
   "source": [
    "## Adding Memory In Agentic Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Hello my name is KRish\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"What is my name\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stategraph\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "## Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "## Grpah\n",
    "builder=StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "\n",
    "## compile the graph\n",
    "graph=builder.compile(checkpointer=memory)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "\n",
    "response=graph.invoke({\"messages\":\"Hi my name is Krish\"},config=config)\n",
    "\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904463e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363227cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Hey what is my name\"},config=config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53567d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=graph.invoke({\"messages\":\"Hey do you remember mmy name\"},config=config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b3d4d",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory=MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bca6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def superbot(state:State):\n",
    "    return {\"messages\":[llm.invoke(state['messages'])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433922c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(State)\n",
    "\n",
    "## node\n",
    "graph.add_node(\"SuperBot\",superbot)\n",
    "## Edges\n",
    "\n",
    "graph.add_edge(START,\"SuperBot\")\n",
    "graph.add_edge(\"SuperBot\",END)\n",
    "\n",
    "\n",
    "graph_builder=graph.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "## Display\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph_builder.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Invocation\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "graph_builder.invoke({'messages':\"Hi,My name is Krish And I like cricket\"},config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14a6a0",
   "metadata": {},
   "source": [
    "### Streaming \n",
    "Methods: .stream() and astream()\n",
    "\n",
    "- These methods are sync and async methods for streaming back results.\n",
    "\n",
    "Additional parameters in streaming modes for graph state\n",
    "\n",
    "- **values** : This streams the full state of the graph after each node is called.\n",
    "- **updates** : This streams updates to the state of the graph after each node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "for chunk in graph_builder.stream({'messages':\"Hi,My name is Krish And I like cricket\"},config,stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefc7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph_builder.stream({'messages':\"Hi,My name is Krish And I like cricket\"},config,stream_mode=\"values\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "for chunk in graph_builder.stream({'messages':\"Hi,My name is Krish And I like cricket\"},config,stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph_builder.stream({'messages':\"I also like football\"},config,stream_mode=\"values\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e296a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "async for event in graph_builder.astream_events({\"messages\":[\"Hi My name is Krish and I like to play cricket\"]},config,version=\"v2\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4326d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
